{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1.0 Environment Setup"
      ],
      "metadata": {
        "id": "Z4AeeMChbLtz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO0nJVqdatqI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.0 Mount Drive"
      ],
      "metadata": {
        "id": "WezZjJ8PbUHN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOoL2PN7bmUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.0 Imports and Configuration"
      ],
      "metadata": {
        "id": "5EGXSaoSbmwk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUnUbzybbs8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.0 Build Manifest (Map Feature File and to Slide Label)"
      ],
      "metadata": {
        "id": "7aR8OYQFcJI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A - Build manifest mapping feature .npy -> slide label (numeric)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/WSI-MIL-Pipeline\")\n",
        "FEATURES_DIR = BASE_DIR / \"data\" / \"features\"          # contains slide_XXX_features.npy\n",
        "LABELS_CSV = BASE_DIR / \"data\" / \"stage_labels.csv\"    # your csv with slide-level and patch-level rows\n",
        "\n",
        "# load labels CSV\n",
        "labels_df = pd.read_csv(LABELS_CSV)\n",
        "\n",
        "# We assume slide-level rows are the ones where 'patient' or 'slide' contains \".zip\" or direct slide id.\n",
        "# Adjust this selection depending on your CSV: here we keep rows where value endswith '.zip' or matches a slide id\n",
        "# Try these heuristics:\n",
        "if 'patient' in labels_df.columns:\n",
        "    lab_col = 'patient'\n",
        "elif 'slide_id' in labels_df.columns:\n",
        "    lab_col = 'slide_id'\n",
        "else:\n",
        "    lab_col = labels_df.columns[0]\n",
        "\n",
        "# Create slide-level mapping: choose rows that look like slide identifiers (zip or no \"_node_\")\n",
        "slide_level = labels_df[~labels_df[lab_col].astype(str).str.contains(r\"_node_|node|_patch_\", regex=True)]\n",
        "slide_level = slide_level.copy()\n",
        "\n",
        "# Normalize slide id strings to match your feature filenames.\n",
        "# Example: patient_000.zip -> patient_000  OR patient_000.zip may correspond to slide folder name.\n",
        "def normalize_slide_id(s):\n",
        "    s = str(s)\n",
        "    s = s.replace('.zip','').replace('.svs','').replace('.tif','')\n",
        "    return s\n",
        "\n",
        "slide_level['slide_id'] = slide_level[lab_col].apply(normalize_slide_id)\n",
        "slide_level = slide_level.rename(columns={labels_df.columns[1]: 'label'})  # assume second column is label\n",
        "\n",
        "# numeric encode labels\n",
        "label_map = {lab:i for i, lab in enumerate(sorted(slide_level['label'].unique()))}\n",
        "slide_level['label_idx'] = slide_level['label'].map(label_map)\n",
        "\n",
        "# find feature files and match\n",
        "manifest = []\n",
        "for p in FEATURES_DIR.glob(\"*_features.npy\"):\n",
        "    slide_name = p.stem.replace(\"_features\",\"\")\n",
        "    match = slide_level[slide_level['slide_id']==slide_name]\n",
        "    if not match.empty:\n",
        "        label_idx = int(match['label_idx'].iloc[0])\n",
        "        manifest.append({'slide_id': slide_name, 'feature_path': str(p), 'label': match['label'].iloc[0], 'label_idx': label_idx})\n",
        "    else:\n",
        "        # not found, skip or log\n",
        "        print(\"No slide-level label for:\", slide_name)\n",
        "\n",
        "manifest_df = pd.DataFrame(manifest)\n",
        "print(\"Prepared manifest:\", manifest_df.shape)\n",
        "print(manifest_df.head())\n",
        "\n",
        "# Save manifest\n",
        "manifest_csv = FEATURES_DIR / \"manifest.csv\"\n",
        "manifest_df.to_csv(manifest_csv, index=False)\n",
        "print(\"Saved manifest to:\", manifest_csv)\n"
      ],
      "metadata": {
        "id": "1HIvNcXpcZO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.0 Bag Label (Collate Dataset)"
      ],
      "metadata": {
        "id": "nTgb1zyxchd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B - PyTorch Dataset that yields (features_tensor, label, slide_id)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SlideBagDataset(Dataset):\n",
        "    def __init__(self, manifest_df):\n",
        "        self.df = manifest_df.reset_index(drop=True)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        feats = np.load(row['feature_path'])   # shape (N_instances, feat_dim)\n",
        "        # optionally: shuffle instances for training stability:\n",
        "        # np.random.shuffle(feats)\n",
        "        feats = torch.from_numpy(feats).float()\n",
        "        label = torch.tensor(int(row['label_idx']), dtype=torch.long)\n",
        "        slide_id = row['slide_id']\n",
        "        return feats, label, slide_id\n",
        "\n",
        "# collate_fn: MIL typically uses batch_size=1 (bags of variable size),\n",
        "# or you can batch multiple bags but here we use batch 1 for simplicity\n",
        "def mil_collate(batch):\n",
        "    # batch is list length B (usually 1). we return single bag and label\n",
        "    feats, labels, sids = zip(*batch)\n",
        "    return feats[0].to(device), labels[0].to(device), sids[0]\n",
        "\n",
        "# Usage:\n",
        "import pandas as pd\n",
        "manifest_df = pd.read_csv(FEATURES_DIR / \"manifest.csv\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# split train/test (stratified)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(manifest_df, test_size=0.2, stratify=manifest_df['label_idx'], random_state=42)\n",
        "\n",
        "train_ds = SlideBagDataset(train_df)\n",
        "test_ds  = SlideBagDataset(test_df)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, collate_fn=mil_collate)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=mil_collate)\n",
        "\n",
        "print(\"Train slides:\", len(train_ds), \"Test slides:\", len(test_ds))\n"
      ],
      "metadata": {
        "id": "OEUI29KPcowE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.0 Attention MIL Model"
      ],
      "metadata": {
        "id": "0yMqhQBOc0ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C - Attention MIL model (instance encoder already computed -> pooling + classifier)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AttentionMIL(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=512, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, hidden_dim)\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "    def forward(self, x):\n",
        "        # x: (n_instances, feat_dim)\n",
        "        H = F.relu(self.fc(x))             # (n, hidden)\n",
        "        A = self.attn(H)                   # (n,1)\n",
        "        A = torch.softmax(A, dim=0)        # normalize over instances\n",
        "        M = (A * H).sum(dim=0)             # (hidden,)\n",
        "        out = self.classifier(M.unsqueeze(0))  # (1, n_classes)\n",
        "        return out, A.squeeze(1)\n",
        "\n",
        "# Instantiate\n",
        "feat_example = np.load(manifest_df['feature_path'].iloc[0])\n",
        "in_dim = feat_example.shape[1]\n",
        "num_classes = len(label_map)\n",
        "model = AttentionMIL(in_dim, hidden_dim=512, n_classes=num_classes).to(device)\n",
        "print(\"Model ready. in_dim=\", in_dim, \"n_classes=\", num_classes)\n"
      ],
      "metadata": {
        "id": "WZyQ-fjXc9Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.0 Training and Evaluation"
      ],
      "metadata": {
        "id": "K1d4q6hKdCHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D - Training loop (batch_size=1 bags)\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "EPOCHS = 10\n",
        "best_acc = 0.0\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    trues, preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for feats, label, sid in loader:\n",
        "            out, att = model(feats)  # feats already on device\n",
        "            pred = int(out.argmax(dim=1).cpu().item())\n",
        "            preds.append(pred); trues.append(int(label.cpu().item()))\n",
        "    acc = accuracy_score(trues, preds)\n",
        "    return acc, trues, preds\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for feats, label, sid in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out, att = model(feats)\n",
        "        loss = criterion(out, label.unsqueeze(0))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    train_loss = float(np.mean(losses)) if losses else 0.0\n",
        "    val_acc, _, _ = evaluate(test_loader)\n",
        "    print(f\"Epoch {epoch} loss={train_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), BASE_DIR / \"models\" / \"mil_best.pth\")\n",
        "print(\"Training done. Best val acc:\", best_acc)\n"
      ],
      "metadata": {
        "id": "z0LnHzeQdMlP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}